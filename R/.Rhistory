fx = fn(theta)
if(fx < value) {
par = theta
value = fx
}
if(sqrt(sum((df(theta) ^ 2))) < tol)
break()
else
theta.last = theta
}
output = list("par" = as.vector(par), "value" = value, "iteration" = i, "method" = "sub gradient")
output
}
# Proximal gradient optimisation.
pg = function(theta, fn, df, prox, acl, tol, maxit, h) {
par = theta.prev = theta
t = c(rep(h, maxit %/% 2), h / (1:(maxit - maxit %/% 2)))
if(isTRUE(acl)){
for (i in 1:maxit) {
v = theta + (i - 2) * (theta - theta.prev) / (i + 1)
par = prox(t[i], v - t[i] * df(v))
theta.prev = theta
theta = par
if(is.na(sqrt(sum((df(theta) ^ 2)))))
stop("the subgradient vector is returning undefined value, change stepsize")
if(sqrt(sum((df(theta) ^ 2))) < tol)
break()
}
throw = "accelerated proximal gradient"
}
else{
for (i in 1:maxit) {
par = prox(t[i], theta - t[i] * df(theta))
theta = par
if(is.na(sqrt(sum((df(theta) ^ 2)))))
stop("the subgradient vector is returning undefined value, change stepsize")
if(sqrt(sum((df(theta) ^ 2))) < tol)
break()
}
throw = "proximal gradient"
}
value = fn(par)
output = list("par" = as.vector(par), "value" = value, "iteration" = i, "method" = throw)
output
}
# Co-ordinate descent optimisation.
cd = function(theta, fn, theta_it, tol, maxit) {
for (j in 1:maxit) {
theta.last = theta
for(i in 1:length(theta)) {
theta[i] = theta_it(theta, i)
}
if(sqrt(sum(((theta.last - theta) ^ 2))) < tol)
break
}
value = fn(theta)
output = list("par" = theta, "value" = value, "iteration" = j, "method" = "coordinate descent")
output
}
if(any(method == c("SG", "sg")))
output = sg(theta = theta, fn = fn, df = df, tol = tol, maxit = maxit, h = h)
if(any(method == c("PG", "pg")))
output = pg(theta = theta, fn = fn, df = df, prox = prox, acl = acl,
tol = tol, maxit = maxit, h = h)
if(any(method == c("CD", "cd")))
output = cd(theta = theta, fn = fn, theta_it = theta_it, tol = tol, maxit = maxit)
output
}
nonsmoothOptim(rep(0,p), fn, df, "sg", tol = 1e-7, maxit = 50000, h = 0.8,
prox(lambda), acl = F, theta_it = theta_it)
nonsmoothOptim(rep(0,p), fn, df, "pg", tol = 1e-7, maxit = 500000, h = 0.8,
prox = prox(lambda), acl = F, theta_it = theta_it)
nonsmoothOptim(rep(0,p), fn, df, "pg", tol = 1e-7, maxit = 500000, h = 0.5,
prox = prox(lambda), acl = T, theta_it = theta_it)
nonsmoothOptim(rep(0,p), fn, df, "cd", tol = 1e-7, maxit = 50000, h = 0.1,
prox = prox(lambda), acl = F, theta_it = theta_it)
setwd("github/nonsmoothOptim/R/")
library(devtools)
library(roxygen2)
document()
---
title: "Bayesian Shrinkage"
author: "Tathagata Basu"
date: "16 April 2019"
output: pdf_document
bibliography: mybib.bib
link-citations: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = F)
```{r library, echo=FALSE}
library(LPCM)
library(coda)
library(rjags)
library(glmnet)
library(glmnet)
library(dclone)
library(monomvn)
library(lattice)
# Data
#gaia
data(gaia)
ind = sample(1:nrow(gaia), 500)
x = as.matrix(gaia[ind,5:20])
y = as.matrix(gaia[ind,4])
colnames(x) = paste0(1:16)
y = as.vector(y)
data_gaia <- list(
y = y,
x = x,
p = ncol(x),
N = length(y)
)
data_def = data_gaia
print("The squared-norm of X-inverese is")
norm(ginv(x), type = "2")^2
plot(princomp(x), main = "Principle components of the Gaia dataset")
# Dirichlet-Laplace model
#
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(80000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
b[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
update(DL, 1000)
DL_MCMC = coda.samples(DL, params, 25000)
effectiveSize(DL_MCMC)
# plots
par(mar=c(4, 3, 3, 1))
plot(DL_MCMC)
library(LPCM)
library(coda)
library(rjags)
library(glmnet)
library(dclone)
library(monomvn)
library(lattice)
data(gaia)
ind = sample(1:nrow(gaia), 500)
x = as.matrix(gaia[ind,5:20])
y = as.matrix(gaia[ind,4])
colnames(x) = paste0(1:16)
y = as.vector(y)
data_gaia <- list(
y = y,
x = x,
p = ncol(x),
N = length(y)
)
data_def = data_gaia
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(80000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
b[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
update(DL, 1000)
DL_MCMC = coda.samples(DL, params, 25000)
plot(DL_MCMC)
norm(x)
data_gaia <- list(
y = y,
x = scale(x, scale = F),
p = ncol(x),
N = length(y)
)
data_def = data_gaia
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(80000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
b[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
update(DL, 1000)
DL_MCMC = coda.samples(DL, params, 25000)
plot(DL_MCMC)
data_gaia <- list(
y = scale(y, scale = F),
x = scale(x, scale = F),
p = ncol(x),
N = length(y)
)
data_def = data_gaia
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(80000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
b[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
data_gaia <- list(
y = as.vector(scale(y, scale = F)),
x = scale(x, scale = F),
p = ncol(x),
N = length(y)
)
data_def = data_gaia
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(80000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
b[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
update(DL, 1000)
DL_MCMC = coda.samples(DL, params, 25000)
plot(DL_MCMC)
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(80000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
val[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
ind[j] ~ dbern(prob[j])
prob[j] ~ dunif(0,1)
beta[j] = ind[j] * val [j]
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(80000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
val[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
ind[j] ~ dbern(prob[j])
prob[j] ~ dunif(0,1)
b[j] = ind[j] * val [j]
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
update(DL, 1000)
DL_MCMC = coda.samples(DL, params, 25000)
plot(DL_MCMC)
summary(DL_MCMC)
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(1000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
val[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
ind[j] ~ dbern(prob[j])
prob[j] ~ dunif(0,1)
b[j] = ind[j] * val [j]
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
update(DL, 1000)
DL_MCMC = coda.samples(DL, params, 25000)
plot(DL_MCMC)
DL.string =
"
model {
## Likelihood
for (i in 1:N)
{
mean[i] = mu + inprod(x[i,], b)
y[i] ~ dnorm(mean[i], inv.var)
}
# Prior on the mean
mu ~ dnorm(0,inv.var)
# prior on the precision
inv.var ~ dgamma(100000,1)
sigma2 = 1/inv.var
## Prior on the regression parameters
# hyper-prior on tau
tau ~ dgamma(p*a, 1/2)
# hyper-prior on phi
phi ~ ddirch(rep(a, p))
a ~ dunif(0, 1)
for (j in 1:p)
{
# hyper-prior on psi
psi[j] ~ dexp(2)
# Prior on beta
val[j] ~ dnorm(0, 1/(psi[j]*(phi[j])^2*tau^2))
ind[j] ~ dbern(prob[j])
prob[j] ~ dunif(0,1)
b[j] = ind[j] * val [j]
}
}
"
DL <- textConnection(DL.string)
params = c("b", "mu", "a", "sigma2")
DL <- jags.model(data = data_def,
file = DL,
n.chains = 1,
n.adapt = 4000)
update(DL, 1000)
DL_MCMC = coda.samples(DL, params, 25000)
plot(DL_MCMC)
